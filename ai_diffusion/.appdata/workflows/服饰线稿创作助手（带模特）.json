{
  "0": {
    "inputs": {
      "ckpt_name": "SDXL/juggernautXL_v9Rdphoto2Lightning.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Checkpoint\u52a0\u8f7d\u5668(\u7b80\u6613)"
    }
  },
  "1": {
    "inputs": {
      "preset": "PLUS (high strength)",
      "model": [
        "0",
        0
      ]
    },
    "class_type": "IPAdapterUnifiedLoader",
    "_meta": {
      "title": "IPAdapter\u52a0\u8f7d\u5668"
    }
  },
  "2": {
    "inputs": {
      "control_net_name": "sdxl_cn/controlnet-union-promax-sdxl-1.0.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "ControlNet\u52a0\u8f7d\u5668"
    }
  },
  "3": {
    "inputs": {
      "ckpt_name": "flux/flux1-schnell-fp8.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Checkpoint\u52a0\u8f7d\u5668(\u7b80\u6613)"
    }
  },
  "4": {
    "inputs": {
      "negative": "Black stroke, (nsfw:1.5)\uff0c(more arm:1.2)\uff0c(more leg:1.2)\uff0c(look forward the camera:1.4),(glove:1.7),(cartoon:1.4), Leather material,hair, fur, false, dark, (overexposed: 1.2), distorted, low quality, (high contrast: 1.2), (wrinkled:1.2), (hanging: 1.3),(floating: 1.3), complex background, mottled background, (high reflection material: 1.1)\uff0c(high contrast:1.3), (dark skin:1.2)",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "easy negative",
    "_meta": {
      "title": "\u8d1f\u9762\u63d0\u793a\u8bcd"
    }
  },
  "5": {
    "inputs": {
      "model_name": "Qwen/Qwen2-7B-Instruct"
    },
    "class_type": "Qwen2_ModelLoader_Zho",
    "_meta": {
      "title": "\u26f1\ufe0fQwen2 ModelLoader"
    }
  },
  "6": {
    "inputs": {
      "text": [
        "4",
        0
      ],
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "clip": [
        "0",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP\u6587\u672c\u7f16\u7801\u5668"
    }
  },
  "7": {
    "inputs": {
      "text": "\u53bb\u6389\u63d2\u753b\u548c\u9ed1\u767d\u56fe\u76f8\u5173\u7684\u63cf\u8ff0\uff0c\u628a\u63cf\u8ff0\u6539\u4e3a\u65f6\u5c1a\u7684\u670d\u9970\u3002\u589e\u52a0\u98ce\u683c\u63cf\u8ff0\uff1a\u8d85\u5199\u5b9e\u98ce\u683c\uff0c\u6e05\u6670\u7684\u5e03\u6599\u7eb9\u7406\u3002\n\n\u8981\u6c42\uff1a\n1\uff0c\u7b80\u6d01\u660e\u4e86\uff0c\u53ea\u8f93\u51fa\u7b54\u6848\uff0c\u7eaf\u82f1\u6587\u3002\n2\uff0c\u53bb\u6389\u63d2\u753b\u3001illustration\u3001\u9ed1\u767d\u56fe\u7b49\u6709\u5173\u5361\u901a\u63d2\u753b\u7684\u753b\u9762\u63cf\u8ff0\u3002\n3\uff0c\u53bb\u6389\u6240\u6709\u989c\u8272\u63cf\u8ff0\uff0c\u5f3a\u5316\u8863\u670d\u4e0a\u7684\u56fe\u6848\u63cf\u8ff0\u3002\n4\uff0c\u589e\u52a0\u6216\u5f3a\u5316\u63cf\u8ff0\uff1a",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "CR Text",
    "_meta": {
      "title": "\u6587\u672c"
    }
  },
  "8": {
    "inputs": {
      "lora_name": "flux/portrait-photography.safetensors",
      "strength_model": 0.9500000000000002,
      "strength_clip": 1.0000000000000002,
      "model": [
        "3",
        0
      ],
      "clip": [
        "3",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "LoRA\u52a0\u8f7d\u5668"
    }
  },
  "9": {
    "inputs": {
      "model_name": "sam_vit_h_4b8939.pth",
      "device_mode": "AUTO"
    },
    "class_type": "SAMLoader",
    "_meta": {
      "title": "SAM\u52a0\u8f7d\u5668"
    }
  },
  "10": {
    "inputs": {
      "model_name": "bbox/face_yolov8m.pt"
    },
    "class_type": "UltralyticsDetectorProvider",
    "_meta": {
      "title": "\u68c0\u6d4b\u52a0\u8f7d\u5668"
    }
  },
  "11": {
    "inputs": {
      "text": "Hyper-realistic facial close-up radiates luminous vitality, capturing an 18-year-old Eurasian beauty mid-laughter. Sun-kissed alabaster skin glows with inner warmth, capillaries beneath translucent cheeks pulsing like liquid coral under morning light. Her Slavic-high cheekbones catch golden halos where sunlight diffuses through downy peach fuzz, while the East Asian oval jawline reflects opalescent sheen reminiscent of moonstone. Almond eyes crinkle at the corners with uncontained mirth, irises transformed into molten topaz pools by direct sunlight - amber flecks igniting into solar flares against steel-gray depths.\n\nWind-tousled chestnut waves frame a face where European angularity and Asian softness merge: the sharp Cupid's bow of her lips arches upward into a smile so vivid it activates dimple creases, while fuller Asian lip contours glisten with moisture from recent laughter. Every epidermal detail conspires toward radiance - sweat droplets along her hairline refract prismatic light, vellus hairs on sunlit temples glowing like spun gold filaments. The Slavic nose bridge becomes a luminous ridge where sunlight fractures into spectral micro-beams across poreless skin, while faint epicanthic folds soften eye smiles into crescent moons.\n\nThis is genetic alchemy electrified by joy: sunlight penetrates to the dermal layer, revealing how golden undertones in her East Asian epidermis amplify Caucasian translucency into living bioluminescence. Even the shadows beneath lashes dance with refracted light particles, each microscopic skin valley catching highlights that transform facial topography into a 3D map of luminosity. A living portrait where multicultural beauty becomes pure energy, every skin texture vibrating with captured sunlight.",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "CR Text",
    "_meta": {
      "title": "\u6587\u672c"
    }
  },
  "12": {
    "inputs": {
      "text": "\n5\uff0c\u628a\u201chyper-realistic photograph\u201d\u653e\u5728\u53e5\u9996\u3002\u5f3a\u8c03\uff1a\u68da\u5185\u5c04\u5f71\uff0c\u5e72\u51c0\u7684\u5149\u7167\uff0c\u903c\u771f\u7684\u7167\u7247\uff0c\u8d85\u5199\u5b9e\u98ce\u683c\uff0c\u81ea\u7136\u6293\u62cd\u7167\uff0c\u6e05\u65b0\u660e\u4eae\uff0c\u4f4e\u5bf9\u6bd4\u5ea6\uff0c\u771f\u5b9e\u9ad8\u7ea7\u7684\u8d28\u611f\uff0c\u8d85\u9ad8\u8d28\u91cf\u3002\u5df4\u9ece\u65f6\u88c5\u5468\u6a21\u7279\uff0c\u767d\u7699\u7684\u76ae\u80a4\u3001\u771f\u5b9e\u7684\u76ae\u80a4\u8d28\u611f,\u773c\u775b\u4e0d\u770b\u5411\u955c\u5934,\u6f02\u4eae\u7684\u8138\u3001\u5f00\u6717\u7684\u5fae\u7b11\u3001\u51c6\u786e\u7684\u4eba\u4f53\u7ed3\u6784\u3002\n6\uff0c\u7981\u6b62\u5305\u542b\u6807\u9898\u548c\u7279\u6b8a\u7b26\u53f7\u3002\n7\uff0c\u683c\u5f0f\u4e3a\u9002\u914dflux\u5927\u6a21\u578b\u7684prompt\u3002",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "CR Text",
    "_meta": {
      "title": "\u6587\u672c"
    }
  },
  "13": {
    "inputs": {
      "unet_name": "SuperMerged2.6.safetensors",
      "weight_dtype": "fp8_e4m3fn"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "UNET\u52a0\u8f7d\u5668"
    }
  },
  "14": {
    "inputs": {
      "clip_name1": "clip_l.safetensors",
      "clip_name2": "t5xxl_fp8_e4m3fn.safetensors",
      "type": "flux",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "\u53ccCLIP\u52a0\u8f7d\u5668"
    }
  },
  "15": {
    "inputs": {
      "vae_name": "ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "VAE\u52a0\u8f7d\u5668"
    }
  },
  "16": {
    "inputs": {},
    "class_type": "ETN_KritaCanvas",
    "_meta": {
      "title": "Krita Canvas"
    }
  },
  "17": {
    "inputs": {
      "name": "2. \u53c2\u8003\u56fe\uff08reference image\uff09(tips: \u8bf7\u9009\u62e9\u6240\u9700\u8981\u53c2\u8003\u7684\u56fe\u7247)"
    },
    "class_type": "ETN_KritaImageLayer",
    "_meta": {
      "title": "Krita Image Layer"
    }
  },
  "18": {
    "inputs": {
      "name": "3. \u63d0\u793a\u8bcd\uff08prompt\uff09(tips:\u8bf7\u8f93\u5165\u4f60\u5bf9\u7ebf\u7a3f\u7684\u63cf\u8ff0\u3002)",
      "type": "text",
      "default": "\u9ec4\u8272\u7684\u4e0a\u8863\uff0c\u7ea2\u8272\u77ed\u53d1\uff0c\u9762\u5e26\u5fae\u7b11\uff0c\u5e74\u8f7b\u3001\u5065\u5eb7\u3001\u6d3b\u6cfc\u768418\u5c81\u4e2d\u4fc4\u6df7\u8840\u7f8e\u5973\u3002",
      "min": 0,
      "max": 0
    },
    "class_type": "ETN_Parameter",
    "_meta": {
      "title": "Parameter"
    }
  },
  "19": {
    "inputs": {
      "name": "1. \u5f00\u542f\u53c2\u8003\u56fe\u53c2\u8003\uff08Open reference image reference\uff09(tips: \u5f00\u542f\u540e\uff0c\u8f93\u5165\u7684\u63d0\u793a\u8bcd\u5c06\u4e0d\u8d77\u4f5c\u7528\uff0cAI\u5c06\u901a\u8fc7\u4e0a\u4f20\u7684\u53c2\u8003\u56fe\u63a7\u5236\u751f\u6210)(off:3-on)(on:3-off)",
      "type": "toggle",
      "default": true,
      "min": 0,
      "max": 0
    },
    "class_type": "ETN_Parameter",
    "_meta": {
      "title": "Parameter"
    }
  },
  "20": {
    "inputs": {
      "seed": 135121212950668
    },
    "class_type": "easy seed",
    "_meta": {
      "title": "\u968f\u673a\u79cd"
    }
  },
  "21": {
    "inputs": {
      "anything": [
        "16",
        0
      ]
    },
    "class_type": "easy cleanGpuUsed",
    "_meta": {
      "title": "\u6e05\u7406GPU\u5360\u7528"
    }
  },
  "22": {
    "inputs": {
      "text": "Please provide a detailed description of this image.xxx",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "ZuellniTextString",
    "_meta": {
      "title": "String"
    }
  },
  "23": {
    "inputs": {
      "text": [
        "22",
        0
      ],
      "find": "xxx",
      "replace": "\u4ed6\u662f\u4e00\u4e2a\u9633\u521a\u7684\u7537\u6a21\u7279"
    },
    "class_type": "Text Find and Replace",
    "_meta": {
      "title": "\u6587\u672c\u66ff\u6362"
    }
  },
  "24": {
    "inputs": {
      "text": [
        "22",
        0
      ],
      "find": "xxx",
      "replace": "\u4ed6\u662f\u4e00\u4e2a\u7f8e\u4e3d\u7684\u5973\u6a21\u7279"
    },
    "class_type": "Text Find and Replace",
    "_meta": {
      "title": "\u6587\u672c\u66ff\u6362"
    }
  },
  "25": {
    "inputs": {
      "unet_name": "flux/flux1-dev-fp8-e4m3fn.safetensors",
      "weight_dtype": "fp8_e4m3fn"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "UNET\u52a0\u8f7d\u5668"
    }
  },
  "26": {
    "inputs": {
      "name": "4. \u5973\u6a21\u7279\uff08Female model\uff09(tips:\u6253\u5f00\u4e3a\u5973\u6a21\u7279\uff0c\u5173\u95ed\u4e3a\u7537\u6a21\u7279)",
      "type": "toggle",
      "default": true,
      "min": 0,
      "max": 0
    },
    "class_type": "ETN_Parameter",
    "_meta": {
      "title": "Parameter"
    }
  },
  "27": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "upscale_method": "lanczos",
      "keep_proportion": true,
      "divisible_by": 2,
      "crop": "disabled",
      "image": [
        "21",
        0
      ]
    },
    "class_type": "ImageResizeKJ",
    "_meta": {
      "title": "\u56fe\u50cf\u7f29\u653e\uff08KJ\uff09"
    }
  },
  "28": {
    "inputs": {
      "coarse": "disable",
      "resolution": 1408,
      "image": [
        "21",
        0
      ]
    },
    "class_type": "LineArtPreprocessor",
    "_meta": {
      "title": "LineArt\u827a\u672f\u7ebf\u9884\u5904\u7406\u5668"
    }
  },
  "29": {
    "inputs": {
      "brightness": 3,
      "contrast": 1.0000000000000002,
      "saturation": 1.0000000000000002,
      "image": [
        "28",
        0
      ]
    },
    "class_type": "LayerColor: Brightness & Contrast",
    "_meta": {
      "title": "\u4eae\u5ea6/\u5bf9\u6bd4\u5ea6"
    }
  },
  "30": {
    "inputs": {
      "text": [
        "11",
        0
      ],
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "clip": [
        "14",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP\u6587\u672c\u7f16\u7801\u5668"
    }
  },
  "31": {
    "inputs": {
      "conditioning": [
        "30",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "\u6761\u4ef6\u96f6\u5316"
    }
  },
  "32": {
    "inputs": {
      "prompt": "Please describe the color and pattern of this picture",
      "model": "qwen-vl-max",
      "system_message": "You are a helpful assistant.",
      "temperature": 0.7000000000000001,
      "max_tokens": 1024,
      "detail": "auto",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "image": [
        "17",
        0
      ]
    },
    "class_type": "LLMNodeFull",
    "_meta": {
      "title": "LLM\u9ad8\u7ea7\u8282\u70b9"
    }
  },
  "33": {
    "inputs": {
      "String": [
        "18",
        0
      ],
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "String",
    "_meta": {
      "title": "\u5b57\u7b26\u4e32"
    }
  },
  "34": {
    "inputs": {
      "action": "append",
      "tidy_tags": "no",
      "text_a": "\u7b2c\u4e8c\u6bb5\uff1a",
      "text_b": [
        "32",
        0
      ],
      "text_c": "",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "StringFunction|pysssss",
    "_meta": {
      "title": "\u5b57\u7b26\u4e32\u64cd\u4f5c"
    }
  },
  "35": {
    "inputs": {
      "lora_name": "CCD\u771f\u5b9e\u611f\u5c0f\u7ea2\u4e66\u7f51\u7ea2\u5e05\u54e5\u7f8e\u5973\u566a\u70b9\u7167\u7247_v1.0.safetensors",
      "strength_model": 1.0000000000000002,
      "model": [
        "25",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoRA\u52a0\u8f7d\u5668(\u4ec5\u6a21\u578b)"
    }
  },
  "36": {
    "inputs": {
      "boolean": [
        "26",
        0
      ],
      "on_true": [
        "24",
        0
      ],
      "on_false": [
        "23",
        0
      ]
    },
    "class_type": "Switch any [Crystools]",
    "_meta": {
      "title": "\u5207\u6362\u4efb\u610f"
    }
  },
  "37": {
    "inputs": {
      "boolean": [
        "26",
        0
      ],
      "on_true": [
        "13",
        0
      ],
      "on_false": [
        "35",
        0
      ]
    },
    "class_type": "Switch any [Crystools]",
    "_meta": {
      "title": "\u5207\u6362\u4efb\u610f"
    }
  },
  "38": {
    "inputs": {
      "ckpt_name": "depth_anything_v2_vitl.pth",
      "resolution": 1024,
      "image": [
        "27",
        0
      ]
    },
    "class_type": "DepthAnythingV2Preprocessor",
    "_meta": {
      "title": "DepthAnythingV2\u6df1\u5ea6\u9884\u5904\u7406\u5668"
    }
  },
  "39": {
    "inputs": {
      "brightness": 0.6000000000000001,
      "contrast": 3,
      "saturation": 1.0000000000000002,
      "image": [
        "38",
        0
      ]
    },
    "class_type": "LayerColor: Brightness & Contrast",
    "_meta": {
      "title": "\u4eae\u5ea6/\u5bf9\u6bd4\u5ea6"
    }
  },
  "40": {
    "inputs": {
      "brightness": 0.6000000000000001,
      "contrast": 3,
      "saturation": 1.0000000000000002,
      "image": [
        "39",
        0
      ]
    },
    "class_type": "LayerColor: Brightness & Contrast",
    "_meta": {
      "title": "\u4eae\u5ea6/\u5bf9\u6bd4\u5ea6"
    }
  },
  "41": {
    "inputs": {
      "channel": "red",
      "image": [
        "40",
        0
      ]
    },
    "class_type": "ImageToMask",
    "_meta": {
      "title": "\u56fe\u50cf\u5230\u906e\u7f69"
    }
  },
  "42": {
    "inputs": {
      "width": 1280,
      "height": 1280,
      "upscale_method": "lanczos",
      "keep_proportion": true,
      "divisible_by": 2,
      "crop": "disabled",
      "image": [
        "27",
        0
      ]
    },
    "class_type": "ImageResizeKJ",
    "_meta": {
      "title": "\u56fe\u50cf\u7f29\u653e\uff08KJ\uff09"
    }
  },
  "43": {
    "inputs": {
      "width": [
        "27",
        1
      ],
      "height": [
        "27",
        2
      ],
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "\u7a7aLatent"
    }
  },
  "44": {
    "inputs": {
      "mask": [
        "41",
        0
      ]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "\u906e\u7f69\u5230\u56fe\u50cf"
    }
  },
  "45": {
    "inputs": {
      "images": [
        "44",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "\u9884\u89c8\u56fe\u50cf"
    }
  },
  "46": {
    "inputs": {
      "mask": [
        "41",
        0
      ]
    },
    "class_type": "InvertMask (segment anything)",
    "_meta": {
      "title": "\u53cd\u8f6c\u906e\u7f69"
    }
  },
  "47": {
    "inputs": {
      "images": [
        "29",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "\u9884\u89c8\u56fe\u50cf"
    }
  },
  "48": {
    "inputs": {
      "width": [
        "42",
        1
      ],
      "height": [
        "42",
        2
      ],
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "\u7a7aLatent"
    }
  },
  "49": {
    "inputs": {
      "prompt": [
        "36",
        0
      ],
      "model": "qwen-vl-max",
      "system_message": "You are a helpful assistant.",
      "temperature": 0.7000000000000001,
      "max_tokens": 1024,
      "detail": "auto",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "image": [
        "27",
        0
      ]
    },
    "class_type": "LLMNodeFull",
    "_meta": {
      "title": "LLM\u9ad8\u7ea7\u8282\u70b9"
    }
  },
  "50": {
    "inputs": {
      "action": "append",
      "tidy_tags": "no",
      "text_a": "\u7b2c\u4e00\u6bb5\uff1a",
      "text_b": [
        "49",
        0
      ],
      "text_c": "",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "StringFunction|pysssss",
    "_meta": {
      "title": "\u5b57\u7b26\u4e32\u64cd\u4f5c"
    }
  },
  "51": {
    "inputs": {
      "text": [
        "49",
        0
      ]
    },
    "class_type": "ShowText|pysssss",
    "_meta": {
      "title": "\u5c55\u793a\u6587\u672c"
    }
  },
  "52": {
    "inputs": {
      "action": "append",
      "tidy_tags": "yes",
      "text_a": "(Realistic: 1.5), (Photo: 1.5), (Photography: 1.5), (Real People: 1.5), (Realistic: 1.5), (Commercial Photography: 1.5)",
      "text_b": [
        "50",
        0
      ],
      "text_c": [
        "34",
        0
      ],
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "StringFunction|pysssss",
    "_meta": {
      "title": "\u5b57\u7b26\u4e32\u64cd\u4f5c"
    }
  },
  "53": {
    "inputs": {
      "prompt": [
        "52",
        0
      ],
      "model": "qwen-max",
      "system_message": "1. Please adjust the prompt words according to the description given to you. The first paragraph provides an overall description of the clothing, movements, background, shoes, etc. worn by the model, while the second paragraph describes the color scheme of the clothes worn by the model.\n3. Extract the color pattern from the second paragraph description and replace the clothing color scheme from the first paragraph. If there is a handbag, the handbag color scheme should also be applied.\n4. The use of black and white lines, sketches, drawings, and other descriptions is prohibited, and only models depicting real people are allowed. Please output prompt words in the following output example format.\n5.The use of black and white lines,and only models depicting real people are allowed.\nOutput example: A young, healthy, and lively 18-year-old Chinese Russian mixed race beauty wearing a yellow striped shirt, with short red hair and a smile on her face.",
      "temperature": 0.7000000000000001,
      "max_tokens": 1024,
      "detail": "auto",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "LLMNodeFull",
    "_meta": {
      "title": "LLM\u9ad8\u7ea7\u8282\u70b9"
    }
  },
  "54": {
    "inputs": {
      "text": [
        "53",
        0
      ]
    },
    "class_type": "ShowText|pysssss",
    "_meta": {
      "title": "\u5c55\u793a\u6587\u672c"
    }
  },
  "55": {
    "inputs": {
      "boolean": [
        "19",
        0
      ],
      "on_true": [
        "54",
        0
      ],
      "on_false": [
        "33",
        0
      ]
    },
    "class_type": "Switch any [Crystools]",
    "_meta": {
      "title": "\u5207\u6362\u4efb\u610f"
    }
  },
  "56": {
    "inputs": {
      "text": [
        "55",
        0
      ],
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "CR Text",
    "_meta": {
      "title": "\u6587\u672c"
    }
  },
  "57": {
    "inputs": {
      "text1": [
        "7",
        0
      ],
      "text2": [
        "56",
        0
      ],
      "separator": ""
    },
    "class_type": "CR Text Concatenate",
    "_meta": {
      "title": "\u6587\u672c\u8054\u7ed3"
    }
  },
  "58": {
    "inputs": {
      "text1": [
        "57",
        0
      ],
      "text2": [
        "12",
        0
      ],
      "separator": ""
    },
    "class_type": "CR Text Concatenate",
    "_meta": {
      "title": "\u6587\u672c\u8054\u7ed3"
    }
  },
  "59": {
    "inputs": {
      "prompt": [
        "56",
        0
      ],
      "model": "qwen-max",
      "system_message": "\u628a\u8fd9\u6bb5\u63cf\u8ff0\u8f6c\u4e3a\u9002\u914dsdxl\u5927\u6a21\u578b\u7684prompt\uff0c\u5168\u82f1\u6587\uff0c\u53ea\u8f93\u51fa\u7ed3\u679c\uff0c\u7981\u6b62\u6709\u6807\u9898\u548c\u7279\u6b8a\u7b26\u53f7\n\n\u8981\u6c42\uff1a\n1\uff0c\u53ea\u8f93\u51fa\u7ed3\u679c\uff0c\u82f1\u6587\uff0c\u82f1\u6587\u7b26\u53f7\u3002\n2\uff0c\u7981\u6b62\u6807\u9898\u548c\u7279\u6b8a\u7b26\u53f7\u548c\u53cc\u5f15\u53f7\u3002",
      "temperature": 0.7000000000000001,
      "max_tokens": 1024,
      "detail": "auto",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "LLMNodeFull",
    "_meta": {
      "title": "LLM\u9ad8\u7ea7\u8282\u70b9"
    }
  },
  "60": {
    "inputs": {
      "prompt": [
        "54",
        0
      ],
      "model": "qwen-max",
      "system_message": [
        "58",
        0
      ],
      "temperature": 0.7000000000000001,
      "max_tokens": 1024,
      "detail": "auto",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "LLMNodeFull",
    "_meta": {
      "title": "LLM\u9ad8\u7ea7\u8282\u70b9"
    }
  },
  "61": {
    "inputs": {
      "prompt": [
        "60",
        0
      ],
      "model": "qwen-max",
      "system_message": "\u628a\u8fd9\u6bb5\u63cf\u8ff0\u8f6c\u4e3a\u9002\u914dsdxl\u5927\u6a21\u578b\u7684prompt\uff0c\u5168\u82f1\u6587\uff0c\u53ea\u8f93\u51fa\u7ed3\u679c\uff0c\u7981\u6b62\u6709\u6807\u9898\u548c\u7279\u6b8a\u7b26\u53f7\n\n\u8981\u6c42\uff1a\n1\uff0c\u53ea\u8f93\u51fa\u7ed3\u679c\uff0c\u82f1\u6587\uff0c\u82f1\u6587\u7b26\u53f7\u3002\n2\uff0c\u7981\u6b62\u6807\u9898\u548c\u7279\u6b8a\u7b26\u53f7\u548c\u53cc\u5f15\u53f7\u3002\n3\uff0c\u5f3a\u8c03\u8d85\u903c\u771f\u56fe\u7247\uff0c\u8d85\u5199\u5b9e\u98ce\u3002\n4\uff0c100\u5b57\u7b26\u4ee5\u5185",
      "temperature": 0.7000000000000001,
      "max_tokens": 1024,
      "detail": "auto",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "LLMNodeFull",
    "_meta": {
      "title": "LLM\u9ad8\u7ea7\u8282\u70b9"
    }
  },
  "62": {
    "inputs": {
      "anything": [
        "60",
        0
      ]
    },
    "class_type": "easy showAnything",
    "_meta": {
      "title": "\u5c55\u793a\u4efb\u4f55"
    }
  },
  "63": {
    "inputs": {
      "text1": [
        "59",
        0
      ],
      "text2": [
        "61",
        0
      ],
      "separator": ","
    },
    "class_type": "CR Text Concatenate",
    "_meta": {
      "title": "\u6587\u672c\u8054\u7ed3"
    }
  },
  "64": {
    "inputs": {
      "text1": [
        "59",
        0
      ],
      "text2": [
        "60",
        0
      ],
      "separator": ","
    },
    "class_type": "CR Text Concatenate",
    "_meta": {
      "title": "\u6587\u672c\u8054\u7ed3"
    }
  },
  "65": {
    "inputs": {
      "action": "append",
      "tidy_tags": "yes",
      "text_a": "(Realistic: 1.5), (Photo: 1.5), (Photography: 1.5), (Real People: 1.5), (Realistic: 1.5), (Commercial Photography: 1.5)",
      "text_b": [
        "63",
        0
      ],
      "text_c": "",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "StringFunction|pysssss",
    "_meta": {
      "title": "\u5b57\u7b26\u4e32\u64cd\u4f5c"
    }
  },
  "66": {
    "inputs": {
      "text": [
        "65",
        0
      ],
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "clip": [
        "0",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP\u6587\u672c\u7f16\u7801\u5668"
    }
  },
  "67": {
    "inputs": {
      "strength": 0.6500000000000001,
      "start_percent": 0.07000000000000002,
      "end_percent": 1,
      "positive": [
        "66",
        0
      ],
      "negative": [
        "6",
        0
      ],
      "control_net": [
        "2",
        0
      ],
      "image": [
        "29",
        0
      ],
      "vae": [
        "0",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "ControlNet\u5e94\u7528\uff08\u65e7\u7248\u9ad8\u7ea7\uff09"
    }
  },
  "68": {
    "inputs": {
      "clip_l": [
        "64",
        0
      ],
      "t5xxl": [
        "64",
        0
      ],
      "guidance": 4.5,
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "clip": [
        "8",
        1
      ]
    },
    "class_type": "CLIPTextEncodeFlux",
    "_meta": {
      "title": "CLIP\u6587\u672c\u7f16\u7801Flux"
    }
  },
  "69": {
    "inputs": {
      "conditioning": [
        "68",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "\u6761\u4ef6\u96f6\u5316"
    }
  },
  "70": {
    "inputs": {
      "seed": [
        "20",
        0
      ],
      "steps": 6,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "beta",
      "denoise": 1,
      "model": [
        "8",
        0
      ],
      "positive": [
        "68",
        0
      ],
      "negative": [
        "69",
        0
      ],
      "latent_image": [
        "48",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "K\u91c7\u6837\u5668"
    }
  },
  "71": {
    "inputs": {
      "text": [
        "63",
        0
      ]
    },
    "class_type": "ShowText|pysssss",
    "_meta": {
      "title": "\u5c55\u793a\u6587\u672c"
    }
  },
  "72": {
    "inputs": {
      "strength": 0.15000000000000002,
      "start_percent": 0.10000000000000002,
      "end_percent": 1,
      "positive": [
        "67",
        0
      ],
      "negative": [
        "67",
        1
      ],
      "control_net": [
        "2",
        0
      ],
      "image": [
        "44",
        0
      ],
      "vae": [
        "0",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "ControlNet\u5e94\u7528\uff08\u65e7\u7248\u9ad8\u7ea7\uff09"
    }
  },
  "73": {
    "inputs": {
      "samples": [
        "70",
        0
      ],
      "vae": [
        "3",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE\u89e3\u7801"
    }
  },
  "74": {
    "inputs": {
      "images": [
        "73",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "\u9884\u89c8\u56fe\u50cf"
    }
  },
  "75": {
    "inputs": {
      "size": "custom",
      "custom_width": 1408,
      "custom_height": 1408,
      "color": "#ffffff",
      "size_as": [
        "73",
        0
      ]
    },
    "class_type": "LayerUtility: ColorImage V2",
    "_meta": {
      "title": "\u7eaf\u8272\u56fe\u50cf_V2"
    }
  },
  "76": {
    "inputs": {
      "weight": 0.6000000000000001,
      "start_at": 0,
      "end_at": 1,
      "weight_type": "standard",
      "model": [
        "1",
        0
      ],
      "ipadapter": [
        "1",
        1
      ],
      "image": [
        "73",
        0
      ],
      "attn_mask": [
        "41",
        0
      ]
    },
    "class_type": "IPAdapter",
    "_meta": {
      "title": "\u5e94\u7528IPAdapter"
    }
  },
  "77": {
    "inputs": {
      "weight": 0.5000000000000001,
      "start_at": 0,
      "end_at": 1,
      "weight_type": "standard",
      "model": [
        "76",
        0
      ],
      "ipadapter": [
        "1",
        1
      ],
      "image": [
        "75",
        0
      ],
      "attn_mask": [
        "46",
        0
      ]
    },
    "class_type": "IPAdapter",
    "_meta": {
      "title": "\u5e94\u7528IPAdapter"
    }
  },
  "78": {
    "inputs": {
      "seed": [
        "20",
        0
      ],
      "steps": 20,
      "cfg": 3.5,
      "sampler_name": "euler",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "77",
        0
      ],
      "positive": [
        "72",
        0
      ],
      "negative": [
        "72",
        1
      ],
      "latent_image": [
        "43",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "K\u91c7\u6837\u5668"
    }
  },
  "79": {
    "inputs": {
      "samples": [
        "78",
        0
      ],
      "vae": [
        "0",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE\u89e3\u7801"
    }
  },
  "80": {
    "inputs": {
      "pixels": [
        "79",
        0
      ],
      "vae": [
        "3",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE\u7f16\u7801"
    }
  },
  "81": {
    "inputs": {
      "seed": 980001631158992,
      "steps": 6,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "beta",
      "denoise": 0.5500000000000002,
      "model": [
        "8",
        0
      ],
      "positive": [
        "68",
        0
      ],
      "negative": [
        "69",
        0
      ],
      "latent_image": [
        "80",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "K\u91c7\u6837\u5668"
    }
  },
  "82": {
    "inputs": {
      "samples": [
        "81",
        0
      ],
      "vae": [
        "3",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE\u89e3\u7801"
    }
  },
  "83": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "upscale_method": "lanczos",
      "keep_proportion": true,
      "divisible_by": 2,
      "crop": "disabled",
      "image": [
        "82",
        0
      ]
    },
    "class_type": "ImageResizeKJ",
    "_meta": {
      "title": "\u56fe\u50cf\u7f29\u653e\uff08KJ\uff09"
    }
  },
  "84": {
    "inputs": {
      "anything": [
        "83",
        0
      ]
    },
    "class_type": "easy cleanGpuUsed",
    "_meta": {
      "title": "\u6e05\u7406GPU\u5360\u7528"
    }
  },
  "85": {
    "inputs": {
      "guide_size": 512,
      "guide_size_for": true,
      "max_size": 1024,
      "seed": 829644618111795,
      "steps": 20,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 0.6500000000000001,
      "feather": 5,
      "noise_mask": true,
      "force_inpaint": true,
      "bbox_threshold": 0.5000000000000001,
      "bbox_dilation": 10,
      "bbox_crop_factor": 3,
      "sam_detection_hint": "center-1",
      "sam_dilation": 0,
      "sam_threshold": 0.9300000000000002,
      "sam_bbox_expansion": 0,
      "sam_mask_hint_threshold": 0.7000000000000002,
      "sam_mask_hint_use_negative": "False",
      "drop_size": 10,
      "wildcard": [
        "11",
        0
      ],
      "cycle": 1,
      "inpaint_model": false,
      "noise_mask_feather": 20,
      "tiled_encode": {
        "__value__": [
          false,
          true
        ]
      },
      "tiled_decode": false,
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "image": [
        "84",
        0
      ],
      "model": [
        "37",
        0
      ],
      "clip": [
        "14",
        0
      ],
      "vae": [
        "15",
        0
      ],
      "positive": [
        "30",
        0
      ],
      "negative": [
        "31",
        0
      ],
      "bbox_detector": [
        "10",
        0
      ],
      "sam_model_opt": [
        "9",
        0
      ]
    },
    "class_type": "FaceDetailer",
    "_meta": {
      "title": "\u9762\u90e8\u7ec6\u5316"
    }
  },
  "86": {
    "inputs": {
      "width": [
        "16",
        1
      ],
      "height": [
        "16",
        2
      ],
      "crop": "disabled",
      "upscale_method": "nearest-exact",
      "lock_aspect_ratio": true,
      "image": [
        "85",
        0
      ]
    },
    "class_type": "EG_TX_SFBLS",
    "_meta": {
      "title": "2\ud83d\udc15Image scaling lock"
    }
  },
  "87": {
    "inputs": {
      "images": [
        "86",
        0
      ]
    },
    "class_type": "ETN_KritaOutput",
    "_meta": {
      "title": "Krita Output"
    }
  }
}