{
  "504": {
    "inputs": {
      "image": "4.jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "\u52a0\u8f7d\u56fe\u50cf"
    }
  },
  "505": {
    "inputs": {
      "caption_type": "Descriptive",
      "caption_length": "long",
      "low_vram": false,
      "joy_two_pipeline": [
        "506",
        0
      ],
      "image": [
        "690",
        0
      ]
    },
    "class_type": "Joy_caption_two",
    "_meta": {
      "title": "Joy Caption Two"
    }
  },
  "506": {
    "inputs": {
      "model": "unsloth/Meta-Llama-3.1-8B-Instruct"
    },
    "class_type": "Joy_caption_two_load",
    "_meta": {
      "title": "Joy Caption Two Load"
    }
  },
  "543": {
    "inputs": {
      "ckpt_name": "depth_anything_v2_vitl.pth",
      "resolution": 1408,
      "image": [
        "690",
        0
      ]
    },
    "class_type": "DepthAnythingV2Preprocessor",
    "_meta": {
      "title": "DepthAnythingV2\u6df1\u5ea6\u9884\u5904\u7406\u5668"
    }
  },
  "545": {
    "inputs": {
      "brightness": 0.6,
      "contrast": 3,
      "saturation": 1,
      "image": [
        "543",
        0
      ]
    },
    "class_type": "LayerColor: Brightness & Contrast",
    "_meta": {
      "title": "\u4eae\u5ea6/\u5bf9\u6bd4\u5ea6"
    }
  },
  "546": {
    "inputs": {
      "brightness": 0.6,
      "contrast": 3,
      "saturation": 1,
      "image": [
        "545",
        0
      ]
    },
    "class_type": "LayerColor: Brightness & Contrast",
    "_meta": {
      "title": "\u4eae\u5ea6/\u5bf9\u6bd4\u5ea6"
    }
  },
  "549": {
    "inputs": {
      "channel": "red",
      "image": [
        "546",
        0
      ]
    },
    "class_type": "ImageToMask",
    "_meta": {
      "title": "\u56fe\u50cf\u5230\u906e\u7f69"
    }
  },
  "563": {
    "inputs": {
      "ckpt_name": "SDXL/juggernautXL_v9Rdphoto2Lightning.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Checkpoint\u52a0\u8f7d\u5668(\u7b80\u6613)"
    }
  },
  "564": {
    "inputs": {
      "seed": 305592853380861,
      "steps": 20,
      "cfg": 3.5,
      "sampler_name": "euler",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "730",
        0
      ],
      "positive": [
        "575",
        0
      ],
      "negative": [
        "575",
        1
      ],
      "latent_image": [
        "664",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "K\u91c7\u6837\u5668"
    }
  },
  "565": {
    "inputs": {
      "text": [
        "787",
        0
      ],
      "speak_and_recognation": true,
      "clip": [
        "563",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP\u6587\u672c\u7f16\u7801\u5668"
    }
  },
  "567": {
    "inputs": {
      "weight": 0.9500000000000001,
      "start_at": 0,
      "end_at": 1,
      "weight_type": "style transfer",
      "model": [
        "568",
        0
      ],
      "ipadapter": [
        "568",
        1
      ],
      "image": [
        "767",
        0
      ],
      "attn_mask": [
        "549",
        0
      ]
    },
    "class_type": "IPAdapter",
    "_meta": {
      "title": "\u5e94\u7528IPAdapter"
    }
  },
  "568": {
    "inputs": {
      "preset": "PLUS (high strength)",
      "model": [
        "563",
        0
      ]
    },
    "class_type": "IPAdapterUnifiedLoader",
    "_meta": {
      "title": "IPAdapter\u52a0\u8f7d\u5668"
    }
  },
  "570": {
    "inputs": {
      "samples": [
        "564",
        0
      ],
      "vae": [
        "563",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE\u89e3\u7801"
    }
  },
  "575": {
    "inputs": {
      "strength": 0.65,
      "start_percent": 0.07,
      "end_percent": 1,
      "positive": [
        "565",
        0
      ],
      "negative": [
        "755",
        0
      ],
      "control_net": [
        "576",
        0
      ],
      "image": [
        "766",
        0
      ],
      "vae": [
        "563",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "ControlNet\u5e94\u7528\uff08\u65e7\u7248\u9ad8\u7ea7\uff09"
    }
  },
  "576": {
    "inputs": {
      "control_net_name": "sdxl_cn/controlnet-union-promax-sdxl-1.0.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "ControlNet\u52a0\u8f7d\u5668"
    }
  },
  "580": {
    "inputs": {
      "clip_l": [
        "752",
        0
      ],
      "t5xxl": [
        "752",
        0
      ],
      "guidance": 3.5,
      "speak_and_recognation": true,
      "clip": [
        "803",
        1
      ]
    },
    "class_type": "CLIPTextEncodeFlux",
    "_meta": {
      "title": "CLIP\u6587\u672c\u7f16\u7801Flux"
    }
  },
  "581": {
    "inputs": {
      "width": 1280,
      "height": 1280,
      "upscale_method": "lanczos",
      "keep_proportion": true,
      "divisible_by": 2,
      "crop": "disabled",
      "image": [
        "690",
        0
      ]
    },
    "class_type": "ImageResizeKJ",
    "_meta": {
      "title": "\u56fe\u50cf\u7f29\u653e\uff08KJ\uff09"
    }
  },
  "582": {
    "inputs": {
      "ckpt_name": "flux/flux1-schnell-fp8.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Checkpoint\u52a0\u8f7d\u5668(\u7b80\u6613)"
    }
  },
  "583": {
    "inputs": {
      "conditioning": [
        "580",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "\u6761\u4ef6\u96f6\u5316"
    }
  },
  "584": {
    "inputs": {
      "samples": [
        "585",
        0
      ],
      "vae": [
        "582",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE\u89e3\u7801"
    }
  },
  "585": {
    "inputs": {
      "seed": [
        "811",
        0
      ],
      "steps": 4,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "beta",
      "denoise": 1,
      "model": [
        "803",
        0
      ],
      "positive": [
        "580",
        0
      ],
      "negative": [
        "583",
        0
      ],
      "latent_image": [
        "797",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "K\u91c7\u6837\u5668"
    }
  },
  "586": {
    "inputs": {
      "images": [
        "584",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "\u9884\u89c8\u56fe\u50cf"
    }
  },
  "664": {
    "inputs": {
      "width": [
        "690",
        1
      ],
      "height": [
        "690",
        2
      ],
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "\u7a7aLatent"
    }
  },
  "666": {
    "inputs": {
      "mask": [
        "549",
        0
      ]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "\u906e\u7f69\u5230\u56fe\u50cf"
    }
  },
  "667": {
    "inputs": {
      "images": [
        "666",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "\u9884\u89c8\u56fe\u50cf"
    }
  },
  "669": {
    "inputs": {
      "samples": [
        "673",
        0
      ],
      "vae": [
        "582",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE\u89e3\u7801"
    }
  },
  "673": {
    "inputs": {
      "seed": 89557248208550,
      "steps": 10,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "beta",
      "denoise": 0.55,
      "model": [
        "803",
        0
      ],
      "positive": [
        "580",
        0
      ],
      "negative": [
        "583",
        0
      ],
      "latent_image": [
        "675",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "K\u91c7\u6837\u5668"
    }
  },
  "675": {
    "inputs": {
      "pixels": [
        "570",
        0
      ],
      "vae": [
        "582",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE\u7f16\u7801"
    }
  },
  "684": {
    "inputs": {
      "amount": 0.3,
      "image": [
        "669",
        0
      ]
    },
    "class_type": "ImageCASharpening+",
    "_meta": {
      "title": "\u56fe\u50cf\u5bf9\u6bd4\u5ea6\u81ea\u9002\u5e94\u9510\u5316"
    }
  },
  "685": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "upscale_method": "lanczos",
      "keep_proportion": true,
      "divisible_by": 2,
      "crop": "disabled",
      "image": [
        "684",
        0
      ]
    },
    "class_type": "ImageResizeKJ",
    "_meta": {
      "title": "\u56fe\u50cf\u7f29\u653e\uff08KJ\uff09"
    }
  },
  "690": {
    "inputs": {
      "width": 1408,
      "height": 1408,
      "upscale_method": "lanczos",
      "keep_proportion": true,
      "divisible_by": 2,
      "crop": "disabled",
      "image": [
        "805",
        0
      ]
    },
    "class_type": "ImageResizeKJ",
    "_meta": {
      "title": "\u56fe\u50cf\u7f29\u653e\uff08KJ\uff09"
    }
  },
  "693": {
    "inputs": {
      "negative": "Black stroke, (nsfw:1.5)\uff0c(more arm:1.2)\uff0c(more leg:1.2)\uff0c(look forward the camera:1.4),(glove:1.7),(cartoon:1.4), Leather material,hair, fur, false, dark, (overexposed: 1.2), distorted, low quality, (high contrast: 1.2), (wrinkled:1.2), (hanging: 1.3),(floating: 1.3), complex background, mottled background, (high reflection material: 1.1)\uff0c(high contrast:1.3), (dark skin:1.2)",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "easy negative",
    "_meta": {
      "title": "\u8d1f\u9762\u63d0\u793a\u8bcd"
    }
  },
  "730": {
    "inputs": {
      "weight": 0.4,
      "start_at": 0,
      "end_at": 1,
      "weight_type": "standard",
      "model": [
        "567",
        0
      ],
      "ipadapter": [
        "568",
        1
      ],
      "image": [
        "732",
        0
      ],
      "attn_mask": [
        "731",
        0
      ]
    },
    "class_type": "IPAdapter",
    "_meta": {
      "title": "\u5e94\u7528IPAdapter"
    }
  },
  "731": {
    "inputs": {
      "mask": [
        "549",
        0
      ]
    },
    "class_type": "InvertMask (segment anything)",
    "_meta": {
      "title": "\u53cd\u8f6c\u906e\u7f69"
    }
  },
  "732": {
    "inputs": {
      "size": "custom",
      "custom_width": 1408,
      "custom_height": 1408,
      "color": "#E6E6E6",
      "size_as": [
        "584",
        0
      ]
    },
    "class_type": "LayerUtility: ColorImage V2",
    "_meta": {
      "title": "\u7eaf\u8272\u56fe\u50cf_V2"
    }
  },
  "750": {
    "inputs": {
      "coarse": "disable",
      "resolution": 1408,
      "image": [
        "805",
        0
      ]
    },
    "class_type": "LineArtPreprocessor",
    "_meta": {
      "title": "LineArt\u827a\u672f\u7ebf\u9884\u5904\u7406\u5668"
    }
  },
  "751": {
    "inputs": {
      "images": [
        "766",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "\u9884\u89c8\u56fe\u50cf"
    }
  },
  "752": {
    "inputs": {
      "prompt": [
        "505",
        0
      ],
      "system_instruction": [
        "790",
        0
      ],
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "model": [
        "753",
        0
      ],
      "tokenizer": [
        "753",
        1
      ]
    },
    "class_type": "Qwen2_Zho",
    "_meta": {
      "title": "\u26f1\ufe0fQwen2"
    }
  },
  "753": {
    "inputs": {
      "model_name": "Qwen/Qwen2-7B-Instruct"
    },
    "class_type": "Qwen2_ModelLoader_Zho",
    "_meta": {
      "title": "\u26f1\ufe0fQwen2 ModelLoader"
    }
  },
  "754": {
    "inputs": {
      "text": "A hyper-realistic photograph of an 18-year-old Eurasian beauty, capturing her youthful vitality and health. Her face radiates with a genuine smile, reflecting her vibrant personality. Dressed in a fashion-forward ensemble, she sports a color-blocked top featuring a subtle graphic of intertwining figures and foliage, offset by a crisp grey pleated skirt. Her outfit, chosen for its contemporary flair, complements her radiant complexion and natural skin texture. Carrying a chic shoulder bag, she exudes confidence and style, akin to a Paris Fashion Week model. The backdrop is a clean, neutral shade, spotlighting her captivating features without distraction. Her eyes, though not directly facing the camera, convey a sense of playfulness and openness, while her body posture suggests a dynamic energy that leaps off the image. This photograph is a testament to high-quality craftsmanship, with meticulous attention to detail and a low-contrast palette that enhances the realism of every element.",
      "anything": [
        "752",
        0
      ]
    },
    "class_type": "easy showAnything",
    "_meta": {
      "title": "\u5c55\u793a\u4efb\u4f55"
    }
  },
  "755": {
    "inputs": {
      "text": [
        "693",
        0
      ],
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "clip": [
        "563",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP\u6587\u672c\u7f16\u7801\u5668"
    }
  },
  "766": {
    "inputs": {
      "brightness": 3,
      "contrast": 1,
      "saturation": 1,
      "image": [
        "750",
        0
      ]
    },
    "class_type": "LayerColor: Brightness & Contrast",
    "_meta": {
      "title": "\u4eae\u5ea6/\u5bf9\u6bd4\u5ea6"
    }
  },
  "767": {
    "inputs": {
      "boolean": false,
      "on_true": [
        "807",
        0
      ],
      "on_false": [
        "584",
        0
      ]
    },
    "class_type": "Switch any [Crystools]",
    "_meta": {
      "title": "\u5207\u6362\u4efb\u610f"
    }
  },
  "787": {
    "inputs": {
      "prompt": [
        "752",
        0
      ],
      "system_instruction": "\u628a\u8fd9\u6bb5\u63cf\u8ff0\u8f6c\u4e3a\u9002\u914dsdxl\u5927\u6a21\u578b\u7684prompt\uff0c\u5168\u82f1\u6587\uff0c\u53ea\u8f93\u51fa\u7ed3\u679c\uff0c\u7981\u6b62\u6709\u6807\u9898\u548c\u7279\u6b8a\u7b26\u53f7\n\n\u8981\u6c42\uff1a\n1\uff0c\u53ea\u8f93\u51fa\u7ed3\u679c\uff0c\u82f1\u6587\uff0c\u82f1\u6587\u7b26\u53f7\u3002\n2\uff0c\u7981\u6b62\u6807\u9898\u548c\u7279\u6b8a\u7b26\u53f7\u548c\u53cc\u5f15\u53f7\u3002\n3\uff0c\u5f3a\u8c03\u8d85\u903c\u771f\u56fe\u7247\uff0c\u8d85\u5199\u5b9e\u98ce\u3002\n4\uff0c\u79ef\u6781\u9633\u5149\uff0c\u5065\u5eb7\u5411\u4e0a\n5\uff0c100\u5b57\u7b26\u4ee5\u5185",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "model": [
        "753",
        0
      ],
      "tokenizer": [
        "753",
        1
      ]
    },
    "class_type": "Qwen2_Zho",
    "_meta": {
      "title": "\u26f1\ufe0fQwen2"
    }
  },
  "788": {
    "inputs": {
      "text2": "Hyper-realistic portrait of a 18-year-old Eurasian, exuding youth & vitality. Wearing a modern, color-blocked top with a graphic motif, paired with a crisp grey pleated skirt. Radiant, confident, Parisian-style elegance. Neutral backdrop highlights captivating features, emphasizing her playful yet open demeanor. Meticulously crafted, showcasing high-quality details in a realistic, low-contrast setting.",
      "text": [
        "787",
        0
      ]
    },
    "class_type": "ShowText|pysssss",
    "_meta": {
      "title": "\u5c55\u793a\u6587\u672c"
    }
  },
  "790": {
    "inputs": {
      "text": "\u53bb\u6389\u63d2\u753b\u548c\u9ed1\u767d\u56fe\u76f8\u5173\u7684\u63cf\u8ff0\uff0c\u628a\u63cf\u8ff0\u6539\u4e3a\u65f6\u5c1a\u7684\u670d\u9970\uff0c\u628a\u767d\u8272\u8863\u670d\u968f\u673a\u66f4\u6539\u4e3a\u5176\u4ed6\u989c\u8272\u3002\u589e\u52a0\u98ce\u683c\u63cf\u8ff0\uff1a\u8d85\u5199\u5b9e\u98ce\u683c\uff0c\u6e05\u6670\u7684\u5e03\u6599\u7eb9\u7406\u3002\u589e\u52a0\u4eba\u7269\u63cf\u8ff0\uff1a\u65f6\u5c1a\u524d\u536b\uff0c\u9762\u5e26\u5fae\u7b11\uff0c\u5e74\u8f7b\u3001\u5065\u5eb7\u3001\u6d3b\u6cfc\u768418\u5c81\u4e2d\u4fc4\u6df7\u8840\u7f8e\u5973\u3002\n\n\u8981\u6c42\uff1a\n1\uff0c\u7b80\u6d01\u660e\u4e86\uff0c\u53ea\u8f93\u51fa\u7b54\u6848\uff0c\u7eaf\u82f1\u6587\u3002\n2\uff0c\u53bb\u6389\u63d2\u753b\u3001illustration\u3001\u9ed1\u767d\u56fe\u7b49\u6709\u5173\u5361\u901a\u63d2\u753b\u7684\u753b\u9762\u63cf\u8ff0\u3002\n3\uff0c\u53bb\u6389\u6240\u6709\u989c\u8272\u63cf\u8ff0\uff0c\u5f3a\u5316\u8863\u670d\u4e0a\u7684\u56fe\u6848\u63cf\u8ff0\u3002\n4\uff0c\u5f3a\u8c03\uff1ahyper-realistic photograph\uff0c\u68da\u5185\u5c04\u5f71\uff0c\u5e72\u51c0\u7684\u5149\u7167\uff0c\u903c\u771f\u7684\u7167\u7247\uff0c\u8d85\u5199\u5b9e\u98ce\u683c\uff0c\u81ea\u7136\u6293\u62cd\u7167\uff0c\u6e05\u65b0\u660e\u4eae\uff0c\u4f4e\u5bf9\u6bd4\u5ea6\uff0c\u771f\u5b9e\u9ad8\u7ea7\u7684\u8d28\u611f\uff0c\u8d85\u9ad8\u8d28\u91cf\u3002\n5\uff0c\u589e\u52a0\u6216\u5f3a\u5316\u63cf\u8ff0\uff1a\u9762\u5e26\u5fae\u7b11\uff0c\u5e74\u8f7b\u3001\u5065\u5eb7\u3001\u6d3b\u6cfc\u768418\u5c81\u4e2d\u4fc4\u6df7\u8840\u7f8e\u5973\u3002\u5df4\u9ece\u65f6\u88c5\u5468\u6a21\u7279\uff0c\u767d\u7699\u7684\u76ae\u80a4\u3001\u771f\u5b9e\u7684\u76ae\u80a4\u8d28\u611f,\u773c\u775b\u4e0d\u770b\u5411\u955c\u5934,\u6f02\u4eae\u7684\u8138\u3001\u5f00\u6717\u7684\u5fae\u7b11\u3001\u51c6\u786e\u7684\u4eba\u4f53\u7ed3\u6784\u3002\n6\uff0c\u7981\u6b62\u5305\u542b\u6807\u9898\u548c\u7279\u6b8a\u7b26\u53f7\u3002\n7\uff0c\u683c\u5f0f\u4e3a\u9002\u914dflux\u5927\u6a21\u578b\u7684prompt\u3002",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "CR Text",
    "_meta": {
      "title": "\u6587\u672c"
    }
  },
  "797": {
    "inputs": {
      "width": [
        "581",
        1
      ],
      "height": [
        "581",
        2
      ],
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "\u7a7aLatent"
    }
  },
  "803": {
    "inputs": {
      "lora_name": "flux/portrait-photography.safetensors",
      "strength_model": 0.9500000000000001,
      "strength_clip": 1,
      "model": [
        "582",
        0
      ],
      "clip": [
        "582",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "LoRA\u52a0\u8f7d\u5668"
    }
  },
  "805": {
    "inputs": {},
    "class_type": "ETN_KritaCanvas",
    "_meta": {
      "title": "Krita Canvas"
    }
  },
  "807": {
    "inputs": {
      "name": "Image"
    },
    "class_type": "ETN_KritaImageLayer",
    "_meta": {
      "title": "Krita Image Layer"
    }
  },
  "808": {
    "inputs": {
      "images": [
        "809",
        0
      ]
    },
    "class_type": "ETN_KritaOutput",
    "_meta": {
      "title": "Krita Output"
    }
  },
  "809": {
    "inputs": {
      "width": 512,
      "height": 512,
      "upscale_method": "nearest-exact",
      "keep_proportion": true,
      "divisible_by": 2,
      "crop": "disabled",
      "image": [
        "685",
        0
      ],
      "width_input": [
        "805",
        1
      ],
      "height_input": [
        "805",
        2
      ]
    },
    "class_type": "ImageResizeKJ",
    "_meta": {
      "title": "\u56fe\u50cf\u7f29\u653e\uff08KJ\uff09"
    }
  },
  "811": {
    "inputs": {
      "seed": 0
    },
    "class_type": "easy seed",
    "_meta": {
      "title": "\u968f\u673a\u79cd"
    }
  }
}